{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from logging import StreamHandler, DEBUG, Formatter, FileHandler, getLogger\n",
    "logger = getLogger(__name__)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from LoadDate import loadTrainData, loadTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogDir = 'logs/'\n",
    "SubmitDir = 'data/'\n",
    "SampleSubmitFile = SubmitDir + 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_prob):\n",
    "    '''\n",
    "    gini係数を計算する関数\n",
    "    '''\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Optunaを使用してパラメータチューニング\n",
    "    '''\n",
    "    # クロスバリデーション\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    drop_rate = trial.suggest_uniform('drop_rate', 0, 1.0)\n",
    "    feature_fraction = trial.suggest_uniform('feature_fraction', 0, 1.0)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.8, 1.0)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 5, 1000)\n",
    "    verbosity = trial.suggest_int('verbosity', -1, 1)\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 10, 100000)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 1000)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 5, 500)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 5, 500)\n",
    "\n",
    "    params = {\"objective\": \"binary\",\n",
    "              \"boosting_type\": \"gbdt\",\n",
    " #             \"learning_rate\": learning_rate\n",
    " #             \"num_leaves\": num_leaves,\n",
    " #             \"max_bin\": 256,\n",
    " #             \"feature_fraction\": feature_fraction,\n",
    " #             \"verbosity\": verbosity,\n",
    " #             \"drop_rate\": drop_rate,\n",
    " #             \"is_unbalance\": False,\n",
    " #             \"max_drop\": 50,\n",
    " #             \"min_child_samples\": min_child_samples,\n",
    " #             \"min_child_weight\": min_child_weight,\n",
    " #             \"min_split_gain\": 0,\n",
    " #             \"num_boost_round\": num_boost_round,\n",
    "              \"min_data_in_leaf\": min_data_in_leaf,\n",
    " #             \"subsample\": subsample\n",
    "              }\n",
    "    \n",
    "    # トレーニングデータと検証用データに分割する\n",
    "    for trainIdx, validIdx in cv.split(xTrain, yTrain):\n",
    "        # インデックスが返ってくるため、ilocで行を特定する\n",
    "        # トレーニング用\n",
    "        trn_x = xTrain.iloc[trainIdx, :]\n",
    "        # 検証用\n",
    "        val_x = xTrain.iloc[validIdx, :]\n",
    "\n",
    "        # トレーニング用\n",
    "        trn_y = yTrain[trainIdx]\n",
    "        # 検証用\n",
    "        val_y = yTrain[validIdx]\n",
    "\n",
    "        # **変数名で、キーワードargsとして渡せる\n",
    "        clf = lgb.LGBMClassifier(**params)\n",
    "        # トレーニングデータでモデル作成\n",
    "        clf.fit(trn_x, trn_y, verbose=False)\n",
    "\n",
    "        # 検証用データで予測する\n",
    "        pred = clf.predict_proba(val_x)[:, 1]\n",
    "        # Optunaが最小化の最適化を行うため符号を反転する\n",
    "        scGini = - eval_gini(val_y, pred)\n",
    "\n",
    "        return(scGini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = df.drop('target', axis=1)\n",
    "yTrain = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-02 22:46:43,410] Finished a trial resulted in value: -0.27540932154206366. Current best value is -0.27540932154206366 with parameters: {'drop_rate': 0.07053069513198229, 'feature_fraction': 0.37059684629635137, 'learning_rate': 0.33655180084643166, 'subsample': 0.9589796585607453, 'num_leaves': 632, 'verbosity': -1, 'num_boost_round': 94697, 'min_data_in_leaf': 52, 'min_child_samples': 99, 'min_child_weight': 488}.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop_rate': 0.07053069513198229,\n",
       " 'feature_fraction': 0.37059684629635137,\n",
       " 'learning_rate': 0.33655180084643166,\n",
       " 'subsample': 0.9589796585607453,\n",
       " 'num_leaves': 632,\n",
       " 'verbosity': -1,\n",
       " 'num_boost_round': 94697,\n",
       " 'min_data_in_leaf': 52,\n",
       " 'min_child_samples': 99,\n",
       " 'min_child_weight': 488}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kizashi\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# **変数名で、キーワードargsとして渡せる\n",
    "clf = lgb.LGBMClassifier(**study.best_params)\n",
    "# トレーニングデータでモデル作成\n",
    "clf.fit(xTrain, yTrain, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
